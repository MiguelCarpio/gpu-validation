---
# [bool] Whether to deploy a VM before running tests
deploy_rhelai_enabled: true
# [string] Name of the VM to create and destroy
deploy_rhelai_vm_name: rhel-ai
# [string] URL of the image to use when creating the VM
deploy_rhelai_image_url: https://cloud.centos.org/centos/9-stream/x86_64/images/CentOS-Stream-GenericCloud-9-latest.x86_64.qcow2
# [string] Image name to use when creating the VM
deploy_rhelai_image_name: rhel-ai
# [string] Flavor to use when creating the VM
deploy_rhelai_flavor_name: nvidia
# [string] RAM value for the flavor
deploy_rhelai_flavor_ram: 40960
# [string] CPU value for the flavor
deploy_rhelai_flavor_vcpus: 8
# [string] Disk value for the flavor
deploy_rhelai_flavor_disk: 20
# [string] Number of GPUs for the flavor
deploy_rhelai_flavor_gpus: 1

# [string] Keypair to use when creating the VM
deploy_rhelai_key_name: rhel-ai
# [string] Network to use when creating the VM
deploy_rhelai_net_name: private
# [string] Network to use when creating the VM
deploy_rhelai_security_group: basic
# [string] Floating IP to assign to the VM
deploy_rhelai_floating_ip: 192.168.122.222
# [string] WARNING Where to (over-)write the ssh key. Must match path in inventory
deploy_rhelai_private_key_file: ~/test_keypair.key
# [bool] Whether to clean up the VM before running tests
deploy_rhelai_pre_cleanup_enabled: true
# [bool] Whether to clean up the VM after running tests
deploy_rhelai_post_cleanup_enabled: false
# [string] Where to find RHOSO certificates for openstack.cloud modules
deploy_rhelai_ca_cert_path: /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem

# [string] DNS server to inject into /etc/resolv.conf
dns_server: 192.168.122.1
# [dict] The PCI Device ID and the number of devices expected
pci_devices:
  10de:27b8: 1

model_tests_enabled: true  # Can be disabled for lighter CUDA-only sanity testing
model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0
# [string] (optional) HuggingFace token if required for download
model_download_hf_token:
# [string] (optional) Model registry username if required for download
model_download_registry_username:
# [string] (optional) Model registry password if required for download
model_download_registry_password:
# [string] (optional) Model container tag to download
model_download_release: ''  # Set to '' for TinyLlama
model_download_repository_base: ''  # Set to '' if downloading from HuggingFace
# [float] Performance threshholds
model_perf_max_avg_time_per_tok: !!float "0.03"
model_perf_max_avg_time_to_first_tok: !!float "0.3"

nvidia_repo_url: "https://developer.download.nvidia.com/compute/cuda/repos/rhel9/"
