---
- name: Append --hf-token argument to model download args if specified
  set_fact:
    model_download_extra_args: "--hf-token {{model_download_hf_token | quote}}"
  when: model_download_hf_token

- name: Download the inference model
  become_user: cloud-user
  command:
    cmd: ilab model download --repository {{[model_download_repository_base, model_name] | join('/') | regex_replace('^/','') | quote }} --release latest {{model_download_extra_args}}
    creates: "{{[model_path_base, model_name] | join('/') }}"
  vars:
    ansible_command_timeout: 3600

- name: Create user systemd directory
  file:
    path: /var/home/cloud-user/.config/systemd/user
    state: directory
    mode: '0755'
    owner: cloud-user
    group: cloud-user

- name: Create ilab systemd service on RHEL AI machine
  template:
    src: templates/ilab-serve.service.j2
    dest: /var/home/cloud-user/.config/systemd/user/ilab-serve.service
    owner: cloud-user
    group: cloud-user
    mode: '0755'
  register: serviceconfig

- name: Stop the model serving service
  when: serviceconfig.changed
  become_user: cloud-user
  command:
    cmd: systemctl --user stop ilab-serve.service

- name: Reload systemd config
  become_user: cloud-user
  command:
    cmd: systemctl --user daemon-reload

- name: Start the model serving service
  command:
    cmd: systemctl --user start ilab-serve.service
  become_user: cloud-user

- name: Wait for vllm API to appear
  command:
    cmd: curl -s --show-error http://localhost:8000/
  register: result
  until: result.rc == 0
  retries: 30
  delay: 10